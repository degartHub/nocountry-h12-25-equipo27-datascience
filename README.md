<h2 align="center";">NoCountry H12-25-Equipo27-DataScience</h2>
<h2 align="center";">Proyecto de Predicci√≥n de Atrasos en Vuelos con Machine Learning</h2>

# Descripci√≥n
Este repositorio documenta el desarrollo de un proyecto colaborativo de ciencia de datos enfocado en la predicci√≥n de retrasos en vuelos, realizado por el equipo H12-25-L-Equipo 27 en el marco de la plataforma de simulaci√≥n NoCountry.
El objetivo del proyecto es simular un entorno laboral real mediante el an√°lisis y modelado de datos de vuelos, aplicando t√©cnicas de machine learning para la predicci√≥n de retrasos y el estudio de los factores que los influyen.
El desarrollo se llev√≥ a cabo principalmente utilizando Python y diversas librer√≠as orientadas a la ciencia de datos y la extracci√≥n de informaci√≥n, como Pandas, NumPy, Scikit-learn, Requests, entre otras.

# Objetivo General
Desarrollar un producto m√≠nimo viable (MVP) que permita predecir si un vuelo ser√° puntual o sufrir√° un retraso, a trav√©s del uso de t√©cnicas de ciencia de datos y machine learning.

# Objetivos espec√≠ficos
-	Analizar y comprender un conjunto de datos hist√≥ricos de vuelos, identificando patrones y variables relevantes asociadas a los retrasos.
-	Realizar tareas de limpieza y preprocesamiento de datos, incluyendo el tratamiento de valores faltantes y la transformaci√≥n de variables.
-	Dise√±ar y construir features relevantes
-	Entrenar y comparar modelos de clasificaci√≥n supervisada para la predicci√≥n de retrasos de vuelos.
-	Evaluar el desempe√±o de los modelos utilizando m√©tricas como Accuracy, Precision, Recall y F1-score.
-	Seleccionar el modelo con mejor desempe√±o y serializarlo para su posterior utilizaci√≥n.
-	Documentar el proceso de an√°lisis, modelado y evaluaci√≥n del modelo.

# Alcance del proyecto
-	El proyecto se limita al desarrollo de un modelo de clasificaci√≥n binaria (Puntual / Retrasado).
-	El trabajo tiene un enfoque educativo y experimental, realizado en el contexto de una simulaci√≥n de entorno laboral.

# Datos utilizados
Los datos fueron extra√≠dos desde ‚Äúkaggle‚Äù, tomando un dataset con alrededor de 540.000 registros y 9 columnas, tales como id, aerol√≠nea, vuelo, origen, destino, d√≠a de la semana, tiempo, duraci√≥n y retraso.

# Tecnolog√≠a y herramientas
Para el desarrollo del proyecto se utiliz√≥ Google Colab como entorno de trabajo, empleando notebooks Jupyter y el lenguaje de programaci√≥n Python.
Asimismo, se hizo uso de diversas librer√≠as orientadas a la extracci√≥n, procesamiento y modelado de datos:
- Manipulaci√≥n y an√°lisis de datos:
  - Pandas
  - Numpy

- Machine Learning (scikit-learn):
Se utilizaron varios subm√≥dulos y funciones de scikit-learn para cubrir todo el flujo de modelado:
  - sklearn.model_selection: Divisi√≥n de datos (Entrenamiento/prueba) y validaci√≥n cruzada.
  - sklearn.preprocessing: Transformaci√≥n y escalado de variables.
  - sklearn.impute: manejo de valores faltantes.
  - sklearn.calibration: calibraci√≥n de probabilidades.
  - sklearn.ensemble: Modelo de clasificaci√≥n Gradient Boosting.
  - sklearn.metrics: Metricas de evaluaci√≥n del modelo:
    - accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report

- Serializaci√≥n del modelo:
  - joblib

- Consumo de datos y manejo de solicitudes HTTP:
  - requests
  - requests.adapters
  - urllib3.util.retry

- Utilidades y manejo del sistema:
  - datetime
  - os
  - shutil
  - logging

# Metodolog√≠a
Del dataset anteriormente mencionado, durante la limpieza de datos se eliminaron las columnas "id" y  "flight", adem√°s de crear ciertas variables como "hora de vuelo" y "d√≠a de la semana", para luego crear una nueva variable denominada "fecha_hora_clima", con el fin de obtener datos desde una API de clima (open-meteo) que nos brinden datos como son "temperatura", "velocidad del viento" y "visibilidad".

Para el entrenamiento del modelo se emplearon tanto variables num√©ricas como categ√≥ricas:

- Variables num√©ricas:
  - distancia_km
  - hora_decimal
  - temperatura
  - velocidad_viento
  - visibilidad

- Variables categ√≥ricas:
  - aerolinea
  - origen
  - destino
  - dia_semana
 
Las variables categ√≥ricas fueron transformadas utilizando One-Hot Encoding para permitir su uso en el modelo de machine learning. El dataset fue dividido en conjuntos de entrenamiento y prueba utilizando una proporci√≥n 80/20, garantizando una evaluaci√≥n adecuada del desempe√±o del modelo sobre datos no vistos.

Se entren√≥ un modelo de Gradient Boosting utilizando la implementaci√≥n GradientBoostingClassifier de scikit-learn. Durante esta etapa se realiz√≥ ajuste de hiperpar√°metros con el objetivo de mejorar el rendimiento predictivo del modelo.

El desempe√±o del modelo fue evaluado utilizando diversas m√©tricas de clasificaci√≥n, entre ellas:
- Accuracy
- Precision
- Recall
- F1-score
- ROC-AUC
- 
Asimismo, se gener√≥ un "classification report" para analizar de forma detallada los resultados obtenidos. Finalmente, el modelo entrenado fue serializado utilizando joblib, permitiendo su posterior carga y utilizaci√≥n en otros entornos o aplicaciones.

# Resultados



# Estructura del Repositorio
- `/data`: Datasets utilizados
- `/notebooks`: Notebooks de Jupyter/Colab (ej: an√°lisis exploratorio).
- `/src`: Scripts Python reutilizables (ej: funciones de modelado).
- `/docs`: Documentaci√≥n adicional (ej: planes, reportes).
- `/models`: Modelos guardados (ej: archivos .joblib).
- `/tests`: Pruebas unitarias.
- `/flight-delay-api`: Carpeta para el despliegue de la API Rest.

## Requisitos
- Python 3.11+
- Librer√≠as: `pip install pandas scikit-learn joblib`

# Miembros del Equipo y Roles
- **NS** - Nicolas Serge Wolgan Staffelbach Henao - Machine Learning Operations
- **IC** - Ismael Cerda - Data Engineer
- **LJ** - Luis J√°come - Machine Learning Engineer
- **DA** - Degenhardt David Aragon Hueck - Data Analyst
- **EA** - Eduardo Ayala - Feature Architect

# C√≥mo Contribuir
1. Clona el repositorio: `git clone https://github.com/TuUsuario/nocountry-h12-25-equipo27-datascience.git`
2. Crea una branch: `git checkout -b feature/tu-tarea`
3. Trabaja y commitea: `git add .` y `git commit -m "Descripci√≥n"`
4. Push: `git push origin feature/tu-tarea`
5. Crea un Pull Request en GitHub para revisi√≥n.
6. Usa Issues para tareas pendientes.

# Integraci√≥n con Google Colab
- Guarda notebooks en `/notebooks`.
- Exporta desde Colab directamente a GitHub.

Si tienes preguntas, usa el chat del equipo o crea un Issue.

¬°Vamos equipo! üöÄ
