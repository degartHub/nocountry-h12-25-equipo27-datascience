{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/degartHub/nocountry-h12-25-equipo27-datascience/blob/main/Notebook_Producto_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRODUCTO FINAL"
      ],
      "metadata": {
        "id": "7GiDEDLrVzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTS"
      ],
      "metadata": {
        "id": "JDoGlX_pV1x6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías Utilizadas\n",
        "\n",
        "Se presentan todas la librerías utilizadas junto a su función en el cuaderno a continuación."
      ],
      "metadata": {
        "id": "LLGgjJ5FMQ2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from requests.adapters import HTTPAdapter                 # Controlar la reconexión automática, límites de conexión y sesiones persistentes.\n",
        "from urllib3.util.retry import Retry                      # Configurar reintentos automáticos de solicitudes a la API.\n",
        "from datetime import datetime, timedelta                  # Operar con diferencias de tiempo.\n",
        "from sklearn.model_selection import train_test_split      # Dividir conjuntos de datos en subconjuntos de entrenamiento y prueba.\n",
        "from sklearn.preprocessing import OneHotEncoder           # Convertir variables categóricas en variables numéricas con codificación one-hot.\n",
        "from sklearn.impute import SimpleImputer                  # Manejar valores faltantes reemplazándolos ya sea con la media, mediana, moda o un valor constante.\n",
        "from sklearn.calibration import CalibratedClassifierCV    # Calibrar las probabilidades producidas por un modelo de clasificación.\n",
        "from sklearn.ensemble import GradientBoostingClassifier   # Entrenar modelos de clasificación basados en ensamblado de árboles de decisión mediante boosting.\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,                                       # Medir la proporción de predicciones correctas realizadas por el modelo respecto al total de predicciones.\n",
        "    precision_score,                                      # Medir la proporción de predicciones positivas correctas sobre el total de predicciones positivas realizadas por el modelo.\n",
        "    recall_score,                                         # Medir la proporción de casos positivos reales que el modelo logra identificar correctamente.\n",
        "    f1_score,                                             # Proporcionar una medida equilibrada del rendimiento del modelo.\n",
        "    roc_auc_score,                                         # Evaluar modelos de clasificación\n",
        "    classification_report                                 # Genera un informe detallado con las anteriores métricas para cada clase del modelo.\n",
        ")\n",
        "import pandas as pd                                       # Leer, limpiar, transformar, analizar y resumir datos.\n",
        "import numpy as np                                        # Realizar calculos numéricos.\n",
        "\n",
        "import logging                                            # Depurar, monitorear y documentar el comportamiento en ciertas partes del código.\n",
        "import requests                                           # Realizar solicitudes HTTP para descargar datos de la API.\n",
        "import os                                                 # Guardar cache de archivos y no depender de descargas repetidas.\n",
        "import shutil                                             # Eliminar caché.\n",
        "import joblib                                             # Guardar y cargar modelos entrenados\n"
      ],
      "metadata": {
        "id": "g2VZ6DKWV3Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CARGA"
      ],
      "metadata": {
        "id": "BR-CQC20V3nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# CARGA DE DATOS (DE)\n",
        "# ================================\n",
        "# Dataset a limpiar para realizar el modelo predictivo\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/degartHub/nocountry-h12-25-equipo27-datascience/refs/heads/main/data/Airlines.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "BYkDbR7wV5py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descripción del dataset"
      ],
      "metadata": {
        "id": "Isn4fbzcSWTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "g0wr6nG5Stm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a88bdfe-10cf-49b2-c679-7c0a686c3811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 539383 entries, 0 to 539382\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   id           539383 non-null  int64 \n",
            " 1   Airline      539383 non-null  object\n",
            " 2   Flight       539383 non-null  int64 \n",
            " 3   AirportFrom  539383 non-null  object\n",
            " 4   AirportTo    539383 non-null  object\n",
            " 5   DayOfWeek    539383 non-null  int64 \n",
            " 6   Time         539383 non-null  int64 \n",
            " 7   Length       539383 non-null  int64 \n",
            " 8   Delay        539383 non-null  int64 \n",
            "dtypes: int64(6), object(3)\n",
            "memory usage: 37.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columnas presentes en el dataset:\n",
        "\n",
        "- <u>**id**</u>= Identifica la fila del registro.\n",
        "\n",
        "- <u>**Airline**</u>= Aerolínea.\n",
        "\n",
        "- <u>**Flight**</u>= Número de la aeronave.\n",
        "\n",
        "- <u>**Airport From**</u>= Aeropuerto de origen.\n",
        "\n",
        "- <u>**Airport To**</u>= Aeropuerto de destino.\n",
        "\n",
        "- <u>**DayOfWeek**</u>= Día de la semana (en números).\n",
        "\n",
        "- <u>**Time**</u>= Hora de salida medida en minutos a partir de la medianoche (rango de [10,1439], lo que podría ser el equivalente a un día).\n",
        "\n",
        "- <u>**Lenght**</u>= Duración del vuelo en minutos.\n",
        "\n",
        "- <u>**Delay**</u>= Con retraso (1), sin retraso (0)."
      ],
      "metadata": {
        "id": "6SvZewJxTInA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selección y Limpieza de datos"
      ],
      "metadata": {
        "id": "C2Z1VZCnTYX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se toman datos aleatorios de la tabla para entender su contenido.\n",
        "\n",
        "df.sample(n=5)"
      ],
      "metadata": {
        "id": "s84DzKdIThl_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "5097dda0-8e20-4dda-caba-55e24c7aaabd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id Airline  Flight AirportFrom AirportTo  DayOfWeek  Time  Length  \\\n",
              "377772  377773      EV    5072         BMI       ATL          3   966     104   \n",
              "334371  334372      OO    6432         SLC       DEN          1   615      85   \n",
              "350295  350296      WN     554         RSW       MDW          2   495     180   \n",
              "13432    13433      B6    1417         AUS       LGB          3  1050     195   \n",
              "344454  344455      WN     617         CMH       MDW          1  1140      75   \n",
              "\n",
              "        Delay  \n",
              "377772      1  \n",
              "334371      0  \n",
              "350295      0  \n",
              "13432       0  \n",
              "344454      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66d43075-8e40-4f3e-bb6f-d59296fcfda7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Airline</th>\n",
              "      <th>Flight</th>\n",
              "      <th>AirportFrom</th>\n",
              "      <th>AirportTo</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>Delay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>377772</th>\n",
              "      <td>377773</td>\n",
              "      <td>EV</td>\n",
              "      <td>5072</td>\n",
              "      <td>BMI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>3</td>\n",
              "      <td>966</td>\n",
              "      <td>104</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334371</th>\n",
              "      <td>334372</td>\n",
              "      <td>OO</td>\n",
              "      <td>6432</td>\n",
              "      <td>SLC</td>\n",
              "      <td>DEN</td>\n",
              "      <td>1</td>\n",
              "      <td>615</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350295</th>\n",
              "      <td>350296</td>\n",
              "      <td>WN</td>\n",
              "      <td>554</td>\n",
              "      <td>RSW</td>\n",
              "      <td>MDW</td>\n",
              "      <td>2</td>\n",
              "      <td>495</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13432</th>\n",
              "      <td>13433</td>\n",
              "      <td>B6</td>\n",
              "      <td>1417</td>\n",
              "      <td>AUS</td>\n",
              "      <td>LGB</td>\n",
              "      <td>3</td>\n",
              "      <td>1050</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344454</th>\n",
              "      <td>344455</td>\n",
              "      <td>WN</td>\n",
              "      <td>617</td>\n",
              "      <td>CMH</td>\n",
              "      <td>MDW</td>\n",
              "      <td>1</td>\n",
              "      <td>1140</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66d43075-8e40-4f3e-bb6f-d59296fcfda7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66d43075-8e40-4f3e-bb6f-d59296fcfda7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66d43075-8e40-4f3e-bb6f-d59296fcfda7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 152140,\n        \"min\": 13433,\n        \"max\": 377773,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          334372,\n          344455,\n          350296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Airline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"OO\",\n          \"B6\",\n          \"EV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2742,\n        \"min\": 554,\n        \"max\": 6432,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6432,\n          617,\n          554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AirportFrom\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SLC\",\n          \"CMH\",\n          \"RSW\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AirportTo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"DEN\",\n          \"LGB\",\n          \"ATL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DayOfWeek\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 282,\n        \"min\": 495,\n        \"max\": 1140,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          615,\n          1140,\n          495\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55,\n        \"min\": 75,\n        \"max\": 195,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          75,\n          180\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Delay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Columnas eliminadas\n",
        "\n",
        "- ID: Es un identificador para la tabla en sí\n",
        "- Flight: Identifica el número de avión, no es relevante."
      ],
      "metadata": {
        "id": "9cXeqs3DTueI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=[\"id\", \"Flight\"])"
      ],
      "metadata": {
        "id": "rPV8MvZeT2aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Muestra de datos\n",
        "\n",
        "Al tener un total de 540.000 registros, se reducirá a 20.000 registros, esto tiene como objetivo el no saturar la RAM.\n"
      ],
      "metadata": {
        "id": "CcULz6VnYadp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(n=20000, random_state=20)\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "OdQhZNfZZbmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9634e96b-286c-42de-b250-83da9bf611c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 20000 entries, 213839 to 504223\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Airline      20000 non-null  object\n",
            " 1   AirportFrom  20000 non-null  object\n",
            " 2   AirportTo    20000 non-null  object\n",
            " 3   DayOfWeek    20000 non-null  int64 \n",
            " 4   Time         20000 non-null  int64 \n",
            " 5   Length       20000 non-null  int64 \n",
            " 6   Delay        20000 non-null  int64 \n",
            "dtypes: int64(4), object(3)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimización de espacio"
      ],
      "metadata": {
        "id": "q-J8MYgVZthw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para verificar la memoria utilizada por el dataset en Mb.\n",
        "\n",
        "def memoria_total(df):\n",
        "\n",
        "    mem = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    return f\"{mem:.2f} MB\""
      ],
      "metadata": {
        "id": "4G-lEZMIZzre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de \"Downcasting\", reduce tipo numérico \"int64\" al más pequeño posible.\n",
        "\n",
        "def downcast_numericos(df):\n",
        "\n",
        "    for col in df.select_dtypes(include=[\"int64\"]).columns:\n",
        "      df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "LpOmqGD-Z4o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de cambio de tipo de dato a \"categoría\" (definida por columnas).\n",
        "\n",
        "def categorizar_columnas(df, columnas):\n",
        "\n",
        "    for col in columnas:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(\"category\")\n",
        "        else:\n",
        "            print(f\"Columna '{col}' no encontrada en el DataFrame.\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "W2V8DEptZ41o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para guardar en Parquet.\n",
        "\n",
        "def guardar_parquet(df, nombre_archivo):\n",
        "\n",
        "    df.to_parquet(f\"{nombre_archivo}.parquet\", engine=\"pyarrow\", index=False)\n",
        "    print(f\"{nombre_archivo}.parquet guardado\")"
      ],
      "metadata": {
        "id": "FistzJckZ5Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para limpiar caché (archivos basura).\n",
        "\n",
        "import gc\n",
        "\n",
        "def liberar_memoria():\n",
        "\n",
        "    gc.collect()\n",
        "    print(\"Memoria liberada\")"
      ],
      "metadata": {
        "id": "bFHG2n6kZ-oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se verifica el \"peso\" de los datos antes y después del uso de las funciones anteriormente establecidas.\n",
        "\n",
        "print(f\"df → Uso antes: {memoria_total(df)}\")\n",
        "\n",
        "df = downcast_numericos(df)\n",
        "df = categorizar_columnas(df, [\"Airline\", \"AirportFrom\", \"AirportTo\"])\n",
        "\n",
        "print(f\"df → Uso después: {memoria_total(df)}\")\n",
        "\n",
        "guardar_parquet(df, \"df\")\n",
        "liberar_memoria()"
      ],
      "metadata": {
        "id": "1ZC40lpjaCHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b23dbd9-0b56-459b-d409-770e4f128b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df → Uso antes: 3.72 MB\n",
            "df → Uso después: 0.41 MB\n",
            "df.parquet guardado\n",
            "Memoria liberada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingeniería de datos"
      ],
      "metadata": {
        "id": "SeaPwNs2bkEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creación de columnas hora y día de la semana"
      ],
      "metadata": {
        "id": "2NOsqGdvd1Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "# Crear columnas de hora y día de la semana\n",
        "# -----------------------------------------------------\n",
        "\n",
        "np.random.seed(42)\n",
        "VELOCIDAD_PROMEDIO_KMH = 800\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Renombrar al español para un mejor entendimiento\n",
        "# -----------------------------------------------------\n",
        "df = df.rename(columns={\n",
        "    'Airline': 'aerolinea',\n",
        "    'AirportFrom': 'origen',\n",
        "    'AirportTo': 'destino',\n",
        "    'Length': 'duration_min',\n",
        "    'Delay': 'retraso'  # solo para entrenamiento\n",
        "})\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Calcular distancia en KM\n",
        "# -----------------------------------------------------\n",
        "df['distancia_km'] = (df['duration_min'] / 60) * VELOCIDAD_PROMEDIO_KMH\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Fechas base (DICIEMBRE 2018)\n",
        "# -----------------------------------------------------\n",
        "start_date = pd.to_datetime('2018-12-01')\n",
        "end_date = pd.to_datetime('2018-12-31')\n",
        "random_days = np.random.randint(0, (end_date - start_date).days + 1, size=len(df))\n",
        "df['FlightDate'] = (start_date + pd.to_timedelta(random_days, unit='D')).normalize()\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# FECHA/HORA de salida\n",
        "# -----------------------------------------------------\n",
        "df['DepartureDateTime'] = df['FlightDate'] + pd.to_timedelta(df['Time'], unit='m')\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Fecha partida formato ISO-8601 para modelo\n",
        "# -----------------------------------------------------\n",
        "df['fecha_partida'] = df['DepartureDateTime'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Eliminar columnas que ya no se usan\n",
        "# -----------------------------------------------------\n",
        "df = df.drop(columns=['duration_min'])\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# Verificación de columnas\n",
        "# -----------------------------------------------------\n",
        "print(\"Columnas finales (incluye 'retraso' solo para entrenamiento):\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "qECa99Ulbj5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb939365-6da8-4a7f-b555-4546302f5ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas finales (incluye 'retraso' solo para entrenamiento):\n",
            "       aerolinea origen destino  DayOfWeek  Time  retraso  distancia_km  \\\n",
            "213839        OO    EGE     DEN          1   755        1    706.666667   \n",
            "14809         MQ    DFW     CLE          3  1125        0   1933.333333   \n",
            "221263        UA    DEN     SAN          1  1150        0   1960.000000   \n",
            "194147        MQ    XNA     ORD          7   675        0   1400.000000   \n",
            "234565        AA    BWI     MIA          2   930        0   2333.333333   \n",
            "\n",
            "       FlightDate   DepartureDateTime        fecha_partida  \n",
            "213839 2018-12-07 2018-12-07 12:35:00  2018-12-07T12:35:00  \n",
            "14809  2018-12-20 2018-12-20 18:45:00  2018-12-20T18:45:00  \n",
            "221263 2018-12-29 2018-12-29 19:10:00  2018-12-29T19:10:00  \n",
            "194147 2018-12-15 2018-12-15 11:15:00  2018-12-15T11:15:00  \n",
            "234565 2018-12-11 2018-12-11 15:30:00  2018-12-11T15:30:00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------\n",
        "# Creación de columnas de hora y día de la semana\n",
        "# -----------------------------------------------------\n",
        "# El 'dia_semana' se conserva desde la columna original 'DayOfWeek'.\n",
        "# La columna 'retraso' se mantiene solo para entrenamiento interno.\n",
        "\n",
        "# Convertir 'fecha_partida' a datetime\n",
        "df['fecha_partida_dt'] = pd.to_datetime(df['fecha_partida'])\n",
        "\n",
        "# Crear columna de hora de salida como objeto time (HH:MM)\n",
        "df['hora_salida'] = df['fecha_partida_dt'].dt.time\n",
        "\n",
        "# Conservar día de la semana original desde 'DayOfWeek'\n",
        "df['dia_semana'] = df['DayOfWeek'].astype('int8')  # del dataset original\n",
        "\n",
        "# Reducir memoria: distancia y retraso\n",
        "df['distancia_km'] = df['distancia_km'].astype('float32')\n",
        "df['retraso'] = df['retraso'].astype('uint8')  # binario\n",
        "\n",
        "# Eliminar columnas temporales redundantes\n",
        "#if 'Time' in df.columns:                                                             NS: No eliminamos la columna Time, ya que mide la hora de salida en numeros enteros\n",
        "#    df = df.drop(columns=['Time'])\n",
        "df = df.drop(columns=['fecha_partida_dt'])\n",
        "\n",
        "# Mantener solo columnas necesarias + 'retraso' para entrenamiento\n",
        "df = df[['aerolinea', 'origen', 'destino', 'retraso', 'distancia_km', 'fecha_partida', 'dia_semana', 'hora_salida', 'Time']] #NS: Mantenemos Time para entrenar el modelo.\n",
        "\n",
        "# Verificación rápida\n",
        "print(df.head())\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "3guXpXsyc_ZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48634179-718b-42cc-f718-bd1019b70724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       aerolinea origen destino  retraso  distancia_km        fecha_partida  \\\n",
            "213839        OO    EGE     DEN        1    706.666687  2018-12-07T12:35:00   \n",
            "14809         MQ    DFW     CLE        0   1933.333374  2018-12-20T18:45:00   \n",
            "221263        UA    DEN     SAN        0   1960.000000  2018-12-29T19:10:00   \n",
            "194147        MQ    XNA     ORD        0   1400.000000  2018-12-15T11:15:00   \n",
            "234565        AA    BWI     MIA        0   2333.333252  2018-12-11T15:30:00   \n",
            "\n",
            "        dia_semana hora_salida  Time  \n",
            "213839           1    12:35:00   755  \n",
            "14809            3    18:45:00  1125  \n",
            "221263           1    19:10:00  1150  \n",
            "194147           7    11:15:00   675  \n",
            "234565           2    15:30:00   930  \n",
            "aerolinea        category\n",
            "origen           category\n",
            "destino          category\n",
            "retraso             uint8\n",
            "distancia_km      float32\n",
            "fecha_partida      object\n",
            "dia_semana           int8\n",
            "hora_salida        object\n",
            "Time                int16\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creación columna fecha-hora\n",
        "\n",
        "Se busca obtener datos de la API a partir de la fecha y hora del vuelo (ambos datos contenidos en una misma columna)"
      ],
      "metadata": {
        "id": "Z-Xh9dMpeb6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se cambia el tipo de dato a \"datetime\" (fecha), de la columna \"fecha_partida\".\n",
        "\n",
        "df[\"fecha_partida\"] = pd.to_datetime(df[\"fecha_partida\"])"
      ],
      "metadata": {
        "id": "xnpXsxmic_FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una nueva columna con los datos de la columna \"fecha_partida\", redondeando la hora hacia abajo (ej: 12:40:00 = 12:00:00)\n",
        "# con el fin obtener datos de la API apartir de la fecha y la hora.\n",
        "\n",
        "df[\"fecha_hora_clima\"] = df[\"fecha_partida\"].dt.floor(\"h\")"
      ],
      "metadata": {
        "id": "qBXsOzKUeopz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se verifican los datos la columna creada.\n",
        "\n",
        "df[[\"fecha_hora_clima\"]].head()"
      ],
      "metadata": {
        "id": "mBkKVQENeq7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "aeebb2eb-5a0c-4b5a-f931-3c544a70280c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          fecha_hora_clima\n",
              "213839 2018-12-07 12:00:00\n",
              "14809  2018-12-20 18:00:00\n",
              "221263 2018-12-29 19:00:00\n",
              "194147 2018-12-15 11:00:00\n",
              "234565 2018-12-11 15:00:00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d1eadbf-7638-4039-83db-2ba04aa2c542\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fecha_hora_clima</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213839</th>\n",
              "      <td>2018-12-07 12:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14809</th>\n",
              "      <td>2018-12-20 18:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221263</th>\n",
              "      <td>2018-12-29 19:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194147</th>\n",
              "      <td>2018-12-15 11:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234565</th>\n",
              "      <td>2018-12-11 15:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d1eadbf-7638-4039-83db-2ba04aa2c542')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d1eadbf-7638-4039-83db-2ba04aa2c542 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d1eadbf-7638-4039-83db-2ba04aa2c542');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[[\\\"fecha_hora_clima\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"fecha_hora_clima\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2018-12-07 12:00:00\",\n        \"max\": \"2018-12-29 19:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2018-12-20 18:00:00\",\n          \"2018-12-11 15:00:00\",\n          \"2018-12-29 19:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparación para datos del clima\n",
        "\n"
      ],
      "metadata": {
        "id": "cr-253DIeBrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creación diccionario \"Latitud-Longitud\"\n",
        "\n",
        "Se crea un diccionario con el fin de extraer datos de la API con la ubicación de los aeropuertos."
      ],
      "metadata": {
        "id": "_Fbu6Zu_ks-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset con las ubicaciones de los aeropuertos del dataset a trabajar.\n",
        "\n",
        "url2=\"https://raw.githubusercontent.com/degartHub/nocountry-h12-25-equipo27-datascience/refs/heads/main/data/Aeropuertos.csv\"\n",
        "df_aeropuertos = pd.read_csv(url2)\n",
        "\n",
        "df_aeropuertos.info()"
      ],
      "metadata": {
        "id": "cErZ-eO-k3m_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d6a9db-60d4-4a1c-d348-13a531c8801b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 84343 entries, 0 to 84342\n",
            "Data columns (total 19 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 84343 non-null  int64  \n",
            " 1   ident              84343 non-null  object \n",
            " 2   type               84343 non-null  object \n",
            " 3   name               84343 non-null  object \n",
            " 4   latitude_deg       84343 non-null  float64\n",
            " 5   longitude_deg      84343 non-null  float64\n",
            " 6   elevation_ft       69745 non-null  float64\n",
            " 7   continent          44928 non-null  object \n",
            " 8   iso_country        84051 non-null  object \n",
            " 9   iso_region         84343 non-null  object \n",
            " 10  municipality       79574 non-null  object \n",
            " 11  scheduled_service  84343 non-null  object \n",
            " 12  icao_code          9487 non-null   object \n",
            " 13  iata_code          9062 non-null   object \n",
            " 14  gps_code           43798 non-null  object \n",
            " 15  local_code         35849 non-null  object \n",
            " 16  home_link          4417 non-null   object \n",
            " 17  wikipedia_link     16614 non-null  object \n",
            " 18  keywords           20734 non-null  object \n",
            "dtypes: float64(3), int64(1), object(15)\n",
            "memory usage: 12.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se conservan solo las columnas de latitud, longitud y codigo \"Iata\" que identifica al aeropuerto, con el fin de conectar\n",
        "# nuestro dataset con los datos de la API de clima.\n",
        "\n",
        "df_aeropuertos = df_aeropuertos[[\"latitude_deg\", \"longitude_deg\", \"iata_code\"]]"
      ],
      "metadata": {
        "id": "E4JkqYUhn3Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se verifica la creación de la tabla con las columnas anteriormente mencionadas.\n",
        "\n",
        "df_aeropuertos.info()"
      ],
      "metadata": {
        "id": "_lKjGrjKn6rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d157a16-107d-4aef-93b8-4f6229391982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 84343 entries, 0 to 84342\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   latitude_deg   84343 non-null  float64\n",
            " 1   longitude_deg  84343 non-null  float64\n",
            " 2   iata_code      9062 non-null   object \n",
            "dtypes: float64(2), object(1)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "b_OUCrp_66jE",
        "outputId": "cb7cf318-4392-4c05-924c-aa693ea289d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       aerolinea origen destino  retraso  distancia_km       fecha_partida  \\\n",
              "351000        B6    BDL     MCO        0   2373.333252 2018-12-08 08:48:00   \n",
              "468660        CO    ORD     IAH        1   2200.000000 2018-12-31 05:35:00   \n",
              "10709         AA    PHL     DFW        1   3133.333252 2018-12-22 15:05:00   \n",
              "306214        WN    BUF     MDW        1   1400.000000 2018-12-02 15:55:00   \n",
              "34676         MQ    MIA     MEM        1   2066.666748 2018-12-27 20:40:00   \n",
              "\n",
              "        dia_semana hora_salida  Time    fecha_hora_clima  \n",
              "351000           2    08:48:00   528 2018-12-08 08:00:00  \n",
              "468660           2    05:35:00   335 2018-12-31 05:00:00  \n",
              "10709            3    15:05:00   905 2018-12-22 15:00:00  \n",
              "306214           6    15:55:00   955 2018-12-02 15:00:00  \n",
              "34676            4    20:40:00  1240 2018-12-27 20:00:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1c459e2-44ea-4939-b56a-f0739980e382\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aerolinea</th>\n",
              "      <th>origen</th>\n",
              "      <th>destino</th>\n",
              "      <th>retraso</th>\n",
              "      <th>distancia_km</th>\n",
              "      <th>fecha_partida</th>\n",
              "      <th>dia_semana</th>\n",
              "      <th>hora_salida</th>\n",
              "      <th>Time</th>\n",
              "      <th>fecha_hora_clima</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>351000</th>\n",
              "      <td>B6</td>\n",
              "      <td>BDL</td>\n",
              "      <td>MCO</td>\n",
              "      <td>0</td>\n",
              "      <td>2373.333252</td>\n",
              "      <td>2018-12-08 08:48:00</td>\n",
              "      <td>2</td>\n",
              "      <td>08:48:00</td>\n",
              "      <td>528</td>\n",
              "      <td>2018-12-08 08:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468660</th>\n",
              "      <td>CO</td>\n",
              "      <td>ORD</td>\n",
              "      <td>IAH</td>\n",
              "      <td>1</td>\n",
              "      <td>2200.000000</td>\n",
              "      <td>2018-12-31 05:35:00</td>\n",
              "      <td>2</td>\n",
              "      <td>05:35:00</td>\n",
              "      <td>335</td>\n",
              "      <td>2018-12-31 05:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10709</th>\n",
              "      <td>AA</td>\n",
              "      <td>PHL</td>\n",
              "      <td>DFW</td>\n",
              "      <td>1</td>\n",
              "      <td>3133.333252</td>\n",
              "      <td>2018-12-22 15:05:00</td>\n",
              "      <td>3</td>\n",
              "      <td>15:05:00</td>\n",
              "      <td>905</td>\n",
              "      <td>2018-12-22 15:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306214</th>\n",
              "      <td>WN</td>\n",
              "      <td>BUF</td>\n",
              "      <td>MDW</td>\n",
              "      <td>1</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>2018-12-02 15:55:00</td>\n",
              "      <td>6</td>\n",
              "      <td>15:55:00</td>\n",
              "      <td>955</td>\n",
              "      <td>2018-12-02 15:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34676</th>\n",
              "      <td>MQ</td>\n",
              "      <td>MIA</td>\n",
              "      <td>MEM</td>\n",
              "      <td>1</td>\n",
              "      <td>2066.666748</td>\n",
              "      <td>2018-12-27 20:40:00</td>\n",
              "      <td>4</td>\n",
              "      <td>20:40:00</td>\n",
              "      <td>1240</td>\n",
              "      <td>2018-12-27 20:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1c459e2-44ea-4939-b56a-f0739980e382')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1c459e2-44ea-4939-b56a-f0739980e382 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1c459e2-44ea-4939-b56a-f0739980e382');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"aerolinea\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"CO\",\n          \"MQ\",\n          \"AA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"origen\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ORD\",\n          \"MIA\",\n          \"PHL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"destino\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"IAH\",\n          \"MEM\",\n          \"DFW\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retraso\",\n      \"properties\": {\n        \"dtype\": \"uint8\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distancia_km\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2200.0,\n          2066.666748046875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fecha_partida\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2018-12-02 15:55:00\",\n        \"max\": \"2018-12-31 05:35:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2018-12-31 05:35:00\",\n          \"2018-12-27 20:40:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dia_semana\",\n      \"properties\": {\n        \"dtype\": \"int8\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hora_salida\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"05:35:00\",\n          \"20:40:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"int16\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          335,\n          1240\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fecha_hora_clima\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2018-12-02 15:00:00\",\n        \"max\": \"2018-12-31 05:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2018-12-31 05:00:00\",\n          \"2018-12-27 20:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se obtiene el total de aeropuertos unicos, presentes en nuestro dataset de 20.000 registros.\n",
        "\n",
        "airports_from = df[\"origen\"].unique()\n",
        "airports_to = df[\"destino\"].unique()\n",
        "\n",
        "todos_aeropuertos = set(airports_from) | set(airports_to)\n",
        "\n",
        "len(todos_aeropuertos)"
      ],
      "metadata": {
        "id": "j4QPqqCKn8wU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c69a610-a283-4e42-95cc-d0c1cbf8b29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "291"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una tabla con las coordenadas de los aeropuertos de nuestro dataset de 20.000 registros.\n",
        "\n",
        "df_aeropuertos_filtrado = df_aeropuertos[\n",
        "    df_aeropuertos[\"iata_code\"].isin(todos_aeropuertos)\n",
        "    ][[\"iata_code\", \"latitude_deg\", \"longitude_deg\"]]\n",
        "\n",
        "df_aeropuertos_filtrado.info()"
      ],
      "metadata": {
        "id": "_Nz2suxxn-vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3933635e-8aa8-4a63-d7b3-b0628eea192f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 291 entries, 37905 to 64107\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   iata_code      291 non-null    object \n",
            " 1   latitude_deg   291 non-null    float64\n",
            " 2   longitude_deg  291 non-null    float64\n",
            "dtypes: float64(2), object(1)\n",
            "memory usage: 9.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se toma un dato aleatorio para evaluación más adelante.\n",
        "\n",
        "df_aeropuertos_filtrado.sample(n=1)"
      ],
      "metadata": {
        "id": "3euOHCWIoB-k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "8b458d49-d6a0-4478-cf33-b18465b3a168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      iata_code  latitude_deg  longitude_deg\n",
              "38237       CAE     33.938801     -81.119499"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f70ad0cd-9b79-4afe-a34b-fa9871bb6060\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iata_code</th>\n",
              "      <th>latitude_deg</th>\n",
              "      <th>longitude_deg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38237</th>\n",
              "      <td>CAE</td>\n",
              "      <td>33.938801</td>\n",
              "      <td>-81.119499</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f70ad0cd-9b79-4afe-a34b-fa9871bb6060')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f70ad0cd-9b79-4afe-a34b-fa9871bb6060 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f70ad0cd-9b79-4afe-a34b-fa9871bb6060');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_aeropuertos_filtrado\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"iata_code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CAE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude_deg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 33.938801,\n        \"max\": 33.938801,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          33.938801\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude_deg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -81.119499,\n        \"max\": -81.119499,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -81.119499\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea el diccionario, siendo su estructura \"código iata: latitud, longitud\"\n",
        "\n",
        "dicc_coordenadas = {\n",
        "    row[\"iata_code\"]: {\"lat\": row[\"latitude_deg\"], \"lon\": row[\"longitude_deg\"]}\n",
        "    for _, row in df_aeropuertos_filtrado.iterrows()\n",
        "}"
      ],
      "metadata": {
        "id": "ykJKXuRDoDlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se prueba el diccionario con un código presente en la tabla (dato aleatorio obtenido anteriormente).\n",
        "\n",
        "print(dicc_coordenadas[\"CAE\"])"
      ],
      "metadata": {
        "id": "B18hYdPmoFFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a7a5b7-c082-434f-8c44-28ab445acef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lat': 41.504101, 'lon': -74.104797}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Registros únicos de aeropuertos\n",
        "\n",
        "Esto tiene por objetivo el optimizar las llamadas a la API, evitando descargas innecesarias."
      ],
      "metadata": {
        "id": "-nF1WMhxeufs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Se obtienen las combinaciones únicas de aeropuerto y hora de partida, esto con el fin de reducir el número de consultas a la API de clima\n",
        "# y evitar descargas innecesarias.\n",
        "\n",
        "claves_clima = (\n",
        "    df[[\"origen\", \"fecha_hora_clima\"]]\n",
        "    .dropna()\n",
        "    .drop_duplicates()\n",
        ")"
      ],
      "metadata": {
        "id": "Q81ZI43fermU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una función que convierte los datos horarios de clima en un DataFrame de pandas.\n",
        "\n",
        "def clima_json_a_df(data, aeropuerto):\n",
        "    df = pd.DataFrame(data[\"hourly\"])\n",
        "    df[\"fecha_hora_clima\"] = pd.to_datetime(df[\"time\"]).dt.floor(\"h\")\n",
        "    df[\"origen\"] = aeropuerto\n",
        "    return df.drop(columns=[\"time\"])"
      ],
      "metadata": {
        "id": "06GC80rKjQgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuración y consumo de API"
      ],
      "metadata": {
        "id": "-Le-hAF7jaz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuración API de clima y función fallback\n",
        "\n",
        "La API fue obtenida desde: https://open-meteo.com/\n",
        "\n",
        "El objetivo de la función \"Fallback\", es el ser ejecutada como alternativa cuando la API falle."
      ],
      "metadata": {
        "id": "SGhuJ5j0pDp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración de sesión HTTP con política de reintentos, función de llamada API de clima y función \"Fallback\".\n",
        "\n",
        "api_historica = \"https://archive-api.open-meteo.com/v1/archive\"\n",
        "\n",
        "# Política de reintentos para evitar fallos temporales de la API (que no caiga durante la obtención de datos)\n",
        "sesion = requests.Session()\n",
        "intentos = Retry(\n",
        "    total=5,\n",
        "    backoff_factor=1,\n",
        "    status_forcelist=[502, 503, 504]\n",
        ")\n",
        "sesion.mount(\"https://\", HTTPAdapter(max_retries=intentos))\n",
        "\n",
        "# Función Fallback, utilizada cuando la API falla en entregar datos.\n",
        "def obtener_clima_fallback(fecha_salida_hora, fecha_llegada_hora):\n",
        "    inicio = datetime.fromisoformat(fecha_salida_hora)\n",
        "    fin = datetime.fromisoformat(fecha_llegada_hora)\n",
        "\n",
        "    horas = int((fin - inicio).total_seconds() / 3600) + 1\n",
        "\n",
        "    return {\n",
        "        \"hourly\": {\n",
        "            \"time\": [\n",
        "                (inicio + timedelta(hours=i)).isoformat()\n",
        "                for i in range(horas)\n",
        "            ],\n",
        "            \"temperature_2m\": [6.72] * horas,     #Valor obtenido a través del promedio de la columna con 540.000 registros (aprox)\n",
        "            \"windspeed_10m\": [12.2] * horas,      #Valor obtenido a través del promedio de la columna con 540.000 registros (aprox)\n",
        "            \"weathercode\": [7000],                #Valor obtenido a través del promedio de la columna con 540.000 registros (aprox)\n",
        "        },\n",
        "        \"source\": \"fallback\"\n",
        "    }\n",
        "\n",
        "# Función de llamada a la API, junto con función \"fallback\" en caso de falla.\n",
        "def obtener_clima(lat, lon, fecha_salida_hora, fecha_llegada_hora):\n",
        "    params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"start_date\": fecha_salida_hora,\n",
        "        \"end_date\": fecha_llegada_hora,\n",
        "        \"hourly\": [\n",
        "            \"temperature_2m\",\n",
        "            \"windspeed_10m\",\n",
        "            \"weathercode\"\n",
        "        ],\n",
        "        \"timezone\": \"UTC\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        respuesta = sesion.get(api_historica, params=params, timeout=30)\n",
        "        respuesta.raise_for_status()\n",
        "\n",
        "        return {\n",
        "            \"data\": respuesta.json(),\n",
        "            \"is_fallback\": False\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Fallo la API de clima, usando fallback | {e}\")\n",
        "\n",
        "        return {\n",
        "            \"data\": obtener_clima_fallback(fecha_salida_hora, fecha_llegada_hora),\n",
        "            \"is_fallback\": True\n",
        "        }"
      ],
      "metadata": {
        "id": "azOUjQdYer18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LLamada a la API"
      ],
      "metadata": {
        "id": "alae8necpRFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A continuación, se hace uso de la función de la API de clima para su consumo.\n",
        "\n",
        "dfs_clima = []\n",
        "\n",
        "# Directorio de cache\n",
        "cache_dir = \"cache_clima\"\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "# Fechas únicas por aeropuerto\n",
        "claves_clima = df[[\"origen\", \"fecha_hora_clima\"]].drop_duplicates()\n",
        "\n",
        "for aeropuerto, grupo in claves_clima.groupby(\"origen\"):\n",
        "\n",
        "    if aeropuerto not in dicc_coordenadas:\n",
        "        print(f\"Aeropuerto {aeropuerto} no encontrado. Omitido.\")\n",
        "        continue\n",
        "\n",
        "    coordenadas = dicc_coordenadas[aeropuerto]\n",
        "    fechas = sorted(grupo[\"fecha_hora_clima\"].dt.date.unique())\n",
        "\n",
        "    i = 0\n",
        "    while i < len(fechas):\n",
        "        fecha_inicial = fechas[i]\n",
        "        fecha_final = min(fecha_inicial + timedelta(days=6), fechas[-1])\n",
        "\n",
        "        cache = f\"{cache_dir}/clima_{aeropuerto}_{fecha_inicial}_{fecha_final}.pkl\"\n",
        "\n",
        "        if os.path.exists(cache):\n",
        "            df_temporal = pd.read_pickle(cache)\n",
        "\n",
        "        else:\n",
        "            try:\n",
        "                resultado = obtener_clima(\n",
        "                    lat=coordenadas[\"lat\"],\n",
        "                    lon=coordenadas[\"lon\"],\n",
        "                    fecha_salida_hora=str(fecha_inicial),\n",
        "                    fecha_llegada_hora=str(fecha_final)\n",
        "                )\n",
        "\n",
        "                # Mensaje \"se usó fallback...\"\n",
        "                if resultado[\"is_fallback\"]:\n",
        "                    print(\n",
        "                        f\"Se usó fallback → \"\n",
        "                        f\"{aeropuerto} | {fecha_inicial} a {fecha_final}\"\n",
        "                    )\n",
        "\n",
        "                df_temporal = clima_json_a_df(\n",
        "                    resultado[\"data\"],\n",
        "                    aeropuerto\n",
        "                )\n",
        "\n",
        "                df_temporal[\"fecha_hora_clima\"] = (\n",
        "                    pd.to_datetime(df_temporal[\"fecha_hora_clima\"])\n",
        "                      .dt.floor(\"h\")\n",
        "                )\n",
        "\n",
        "                # Se guarda caché, siempre que no sea fallback\n",
        "                if not resultado[\"is_fallback\"]:\n",
        "                    df_temporal.to_pickle(cache)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(\n",
        "                    f\"Error descargando clima {aeropuerto} \"\n",
        "                    f\"{fecha_inicial}-{fecha_final}: {e}\"\n",
        "                )\n",
        "                i += 7\n",
        "                continue\n",
        "\n",
        "        dfs_clima.append(df_temporal)\n",
        "        i += 7\n",
        "\n",
        "# Concatenar todo\n",
        "df_clima = pd.concat(dfs_clima, ignore_index=True)"
      ],
      "metadata": {
        "id": "iagh73D2oyM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c41f48-d251-42a8-a9b0-290639048607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3610432459.py:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  for aeropuerto, grupo in claves_clima.groupby(\"origen\"):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integración de datos del clima"
      ],
      "metadata": {
        "id": "xraktQl-sqhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unión de datos"
      ],
      "metadata": {
        "id": "5WOp1aXkpWZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se unen las tablas\n",
        "\n",
        "df_nuevo = df.merge(\n",
        "    df_clima,\n",
        "    on=[\"origen\", \"fecha_hora_clima\"],\n",
        "    how=\"left\"\n",
        ")"
      ],
      "metadata": {
        "id": "-6sjFqkipUTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se verifica que las tablas se hayan unido.\n",
        "\n",
        "df_nuevo.info()"
      ],
      "metadata": {
        "id": "AzE4XeKapcoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd58e3c-2a85-4541-85dc-33aac0f4782c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 13 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   aerolinea         20000 non-null  category      \n",
            " 1   origen            20000 non-null  object        \n",
            " 2   destino           20000 non-null  category      \n",
            " 3   retraso           20000 non-null  uint8         \n",
            " 4   distancia_km      20000 non-null  float32       \n",
            " 5   fecha_partida     20000 non-null  datetime64[ns]\n",
            " 6   dia_semana        20000 non-null  int8          \n",
            " 7   hora_salida       20000 non-null  object        \n",
            " 8   Time              20000 non-null  int16         \n",
            " 9   fecha_hora_clima  20000 non-null  datetime64[ns]\n",
            " 10  temperature_2m    18903 non-null  float64       \n",
            " 11  windspeed_10m     18903 non-null  float64       \n",
            " 12  weathercode       18903 non-null  float64       \n",
            "dtypes: category(2), datetime64[ns](2), float32(1), float64(3), int16(1), int8(1), object(2), uint8(1)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Limpieza y preparación de datos de la API\n",
        "\n",
        "Durante la llamada a la API, se tiene el \"código del clima\", mientras que más adelante se renombra esta columna por \"visibilidad\" y se cambian los datos de esta columna por un aproximado en cuanto a la visibilidad en relación al código del clima.\n",
        "\n",
        "La razón de esto es porque se hace uso de la API \"histórica\", en donde no se tienen datos relacionados a"
      ],
      "metadata": {
        "id": "vkgEJiMqpfpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario para estimar visibilidad según \"weathercode\" (código de clima).\n",
        "\n",
        "visibilidad_estimacion = {\n",
        "    0: 10000,   # Despejado\n",
        "    1: 9000,    # Parcialmente nublado\n",
        "    2: 8000,    # Nublado\n",
        "    3: 6000,    # Lluvia ligera\n",
        "    45: 7000,   # Neblina\n",
        "    48: 5000,   # Neblina helada\n",
        "    51: 6000,   # Llovizna ligera\n",
        "    53: 5000,   # Llovizna moderada\n",
        "    55: 4000,   # Llovizna intensa\n",
        "    61: 5000,   # Lluvia ligera\n",
        "    63: 4000,   # Lluvia moderada\n",
        "    65: 3000,   # Lluvia intensa\n",
        "    71: 4000,   # Nieve ligera\n",
        "    73: 3000,   # Nieve moderada\n",
        "    75: 2000,   # Nieve intensa\n",
        "    80: 2500,   # Chubascos ligeros\n",
        "    81: 1500,   # Chubascos moderados\n",
        "    82: 1000,   # Chubascos intensos\n",
        "    95: 500,    # Tormenta\n",
        "    96: 400,    # Tormenta con granizo\n",
        "    99: 300     # Tormenta intensa con granizo\n",
        "}"
      ],
      "metadata": {
        "id": "PEpXtrK5pfZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convierte los códigos de 'weathercode' a valores numéricos, los cuales tienen por objetivo representar la visibilidad.\n",
        "\n",
        "df_nuevo[\"weathercode\"] = df_nuevo[\"weathercode\"].map(visibilidad_estimacion)"
      ],
      "metadata": {
        "id": "jGtiSdBqtQRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se renombran las columnas (traducción al español, en el caso de \"weathercode\", esta representa la visibilidad).\n",
        "\n",
        "df_nuevo = df_nuevo.rename(columns={\n",
        "    'temperature_2m': 'temperatura',\n",
        "    'windspeed_10m': 'velocidad_viento',\n",
        "    \"weathercode\": \"visibilidad\"\n",
        "})"
      ],
      "metadata": {
        "id": "em70lbR4tRuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se verifica que los cambios anteriormente descritos se hayan efectuado\n",
        "\n",
        "df_nuevo.info()"
      ],
      "metadata": {
        "id": "Cco9wPedtUag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120ded95-53f8-48c4-8bb2-9788c1ecca81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 13 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   aerolinea         20000 non-null  category      \n",
            " 1   origen            20000 non-null  object        \n",
            " 2   destino           20000 non-null  category      \n",
            " 3   retraso           20000 non-null  uint8         \n",
            " 4   distancia_km      20000 non-null  float32       \n",
            " 5   fecha_partida     20000 non-null  datetime64[ns]\n",
            " 6   dia_semana        20000 non-null  int8          \n",
            " 7   hora_salida       20000 non-null  object        \n",
            " 8   Time              20000 non-null  int16         \n",
            " 9   fecha_hora_clima  20000 non-null  datetime64[ns]\n",
            " 10  temperatura       18903 non-null  float64       \n",
            " 11  velocidad_viento  18903 non-null  float64       \n",
            " 12  visibilidad       18903 non-null  float64       \n",
            "dtypes: category(2), datetime64[ns](2), float32(1), float64(3), int16(1), int8(1), object(2), uint8(1)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Al observar la tabla anterior, se puede ver que faltan datos, al entregar una gran cantidad de datos a la API, esta entrega información por lotes\n",
        "# lo que lleva a que en el proceso se pierdan algunos datos, para rellenar los datos faltantes, se obtiene el promedio de los datos obtenidos por\n",
        "# columna y se rellenan los espacios vacios con dicho promedio.\n",
        "\n",
        "promedio_temperatura = df_nuevo[\"temperatura\"].mean()\n",
        "promedio_velocidad_viento = df_nuevo[\"velocidad_viento\"].mean()\n",
        "promedio_visibilidad = round(df_nuevo[\"visibilidad\"].mean(), -3)\n",
        "\n",
        "df_nuevo[\"temperatura\"] = df_nuevo[\"temperatura\"].fillna(promedio_temperatura)\n",
        "df_nuevo[\"velocidad_viento\"] = df_nuevo[\"velocidad_viento\"].fillna(promedio_velocidad_viento)\n",
        "df_nuevo[\"visibilidad\"] = df_nuevo[\"visibilidad\"].fillna(promedio_visibilidad)"
      ],
      "metadata": {
        "id": "C8yQ5hZptWTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se verifica que las columnas hayan sido rellenadas con los promedios anteriormente mencionados\n",
        "\n",
        "df_nuevo.info()"
      ],
      "metadata": {
        "id": "tMnPMUsDumsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3a4a0c-2022-4217-81d7-13b8f650fe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 13 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   aerolinea         20000 non-null  category      \n",
            " 1   origen            20000 non-null  object        \n",
            " 2   destino           20000 non-null  category      \n",
            " 3   retraso           20000 non-null  uint8         \n",
            " 4   distancia_km      20000 non-null  float32       \n",
            " 5   fecha_partida     20000 non-null  datetime64[ns]\n",
            " 6   dia_semana        20000 non-null  int8          \n",
            " 7   hora_salida       20000 non-null  object        \n",
            " 8   Time              20000 non-null  int16         \n",
            " 9   fecha_hora_clima  20000 non-null  datetime64[ns]\n",
            " 10  temperatura       20000 non-null  float64       \n",
            " 11  velocidad_viento  20000 non-null  float64       \n",
            " 12  visibilidad       20000 non-null  float64       \n",
            "dtypes: category(2), datetime64[ns](2), float32(1), float64(3), int16(1), int8(1), object(2), uint8(1)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se renombra el dataset nuevo a simplemente \"df\", esto es solo por motivos de comodidad.\n",
        "\n",
        "df = df_nuevo"
      ],
      "metadata": {
        "id": "tRYYPbq0uosY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESAMIENTO"
      ],
      "metadata": {
        "id": "4VntebDJV6Bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La variable \"hora_salida\" fue transformada a una representación numérica (hora_decimal) para permitir su uso en modelos basados en árboles, evitando problemas de conversión y manteniendo la información temporal relevante."
      ],
      "metadata": {
        "id": "H6m8FnBIvtbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir hora_salida a datetime\n",
        "df['hora_salida'] = pd.to_datetime(\n",
        "    df['hora_salida'],\n",
        "    format='%H:%M:%S',\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Crear hora decimal\n",
        "df['hora_decimal'] = (\n",
        "    df['hora_salida'].dt.hour +\n",
        "    df['hora_salida'].dt.minute / 60\n",
        ")\n",
        "\n",
        "# Eliminar columna original\n",
        "df.drop(columns=['hora_salida'], inplace=True)"
      ],
      "metadata": {
        "id": "o-dyt-vMvtQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición de features finales"
      ],
      "metadata": {
        "id": "b0O3eUzcTWEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# PREP – Definición de features\n",
        "# ============================\n",
        "\n",
        "# Variables numéricas utilizadas por el modelo\n",
        "numeric_features = [\n",
        "    'distancia_km',\n",
        "    'hora_decimal',\n",
        "    'temperatura',\n",
        "    'velocidad_viento',\n",
        "    'visibilidad'\n",
        "]\n",
        "\n",
        "# Variables categóricas utilizadas por el modelo\n",
        "categorical_features = [\n",
        "    'aerolinea',\n",
        "    'origen',\n",
        "    'destino',\n",
        "    'dia_semana'\n",
        "]\n",
        "\n",
        "# Variable objetivo\n",
        "target = 'retraso'\n",
        "\n"
      ],
      "metadata": {
        "id": "fyvXu_zwV8-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Definición de variables de entrada\n",
        "\n",
        "En esta etapa se definen explícitamente las variables utilizadas por el modelo final\n",
        "de Machine Learning (Gradient Boosting).\n",
        "\n",
        "Las variables numéricas representan información operativa del vuelo, la hora de salida\n",
        "(expresada en formato decimal para facilitar su uso por el modelo) y condiciones\n",
        "climáticas relevantes.  \n",
        "Las variables categóricas capturan información propia del vuelo y su contexto temporal.\n",
        "\n",
        "Este conjunto de variables corresponde al contrato de entrada del modelo en producción\n",
        "y se mantiene consistente entre el entrenamiento y la inferencia."
      ],
      "metadata": {
        "id": "1-hCZ-k9XtBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# PREPROCESAMIENTO - Manejo de valores faltantes\n",
        "# ======================================\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Imputador para variables numéricas\n",
        "# Se utiliza la mediana por su robustez frente a valores atípicos\n",
        "num_imputer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "# Ajuste del imputador sobre las variables numéricas\n",
        "X_num = num_imputer.fit_transform(df[numeric_features])\n"
      ],
      "metadata": {
        "id": "8Fd4OcHfV9A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manejo de valores faltantes\n",
        "\n",
        "Si bien el dataset utilizado para el entrenamiento del modelo ya cuenta con los valores\n",
        "faltantes tratados, se documenta este paso como parte del pipeline de Machine Learning\n",
        "para asegurar la robustez del modelo en producción.\n",
        "\n",
        "En un entorno productivo, es posible que la información recibida desde la API no esté\n",
        "completa. Por esta razón, el modelo contempla un proceso de imputación sobre las variables\n",
        "numéricas, utilizando la mediana como estadístico de reemplazo por su estabilidad frente\n",
        "a valores atípicos.\n",
        "\n",
        "Este comportamiento se replica durante la inferencia para evitar errores en tiempo de ejecución.\n"
      ],
      "metadata": {
        "id": "joiRVyOuY-rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding de variables categóricas"
      ],
      "metadata": {
        "id": "eObIfb7Ybq67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# PREPROCESAMIENTO - One-Hot Encoding\n",
        "# ======================================\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Encoder para variables categóricas\n",
        "onehot_encoder = OneHotEncoder(\n",
        "    handle_unknown=\"ignore\",\n",
        "    sparse_output=False\n",
        ")\n",
        "\n",
        "# Ajuste y transformación de variables categóricas\n",
        "X_cat = onehot_encoder.fit_transform(df[categorical_features])\n",
        "\n",
        "# Conversión a DataFrame para mantener nombres de columnas\n",
        "X_cat = pd.DataFrame(\n",
        "    X_cat,\n",
        "    columns=onehot_encoder.get_feature_names_out(categorical_features),\n",
        "    index=df.index\n",
        ")\n"
      ],
      "metadata": {
        "id": "dSY_Q-gGV9Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Codificación de variables categóricas\n",
        "\n",
        "Las variables categóricas se transforman mediante One-Hot Encoding para convertirlas\n",
        "en una representación numérica compatible con el modelo de Machine Learning.\n",
        "\n",
        "El encoder se configura para ignorar categorías no vistas durante el entrenamiento,\n",
        "lo que permite que el modelo sea robusto frente a nuevos valores recibidos en producción.\n",
        "\n",
        "Este encoder es parte fundamental del pipeline y se serializa junto con el modelo,\n",
        "ya que define la estructura exacta de las variables de entrada."
      ],
      "metadata": {
        "id": "IUe_SqNdd6NK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construcción del feature matrix final"
      ],
      "metadata": {
        "id": "anqVsaYxb6Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# PREPROCESAMIENTO - Feature Matrix final\n",
        "# ======================================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Conversión de variables numéricas a DataFrame\n",
        "X_num = pd.DataFrame(\n",
        "    X_num,\n",
        "    columns=numeric_features,\n",
        "    index=df.index\n",
        ")\n",
        "\n",
        "# Concatenación de variables numéricas y categóricas\n",
        "X = pd.concat([X_num, X_cat], axis=1)\n",
        "\n",
        "# Variable objetivo\n",
        "y = df[target]\n"
      ],
      "metadata": {
        "id": "qVPbZDdWcCOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Construcción de la matriz final de características\n",
        "\n",
        "Una vez procesadas las variables numéricas y categóricas, ambas se concatenan para\n",
        "construir la matriz final de características utilizada por el modelo.\n",
        "\n",
        "Mantener el orden y la consistencia de las columnas es fundamental, ya que el modelo\n",
        "espera recibir los datos en la misma estructura definida durante el entrenamiento.\n",
        "Esta matriz representa la entrada directa al modelo en el entorno de producción."
      ],
      "metadata": {
        "id": "656LJmNod_0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "qIpkxH0xV-eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo final: Gradient Boosting"
      ],
      "metadata": {
        "id": "8_uyODM-e_ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# ENTRENAMIENTO - Modelo final\n",
        "# ======================================\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Definición del modelo final seleccionado\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Entrenamiento del modelo sobre el dataset procesado\n",
        "# gb_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Dv-ByEcKV_1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento del modelo Gradient Boosting\n",
        "\n",
        "Durante la fase de experimentación se evaluaron distintos algoritmos de clasificación.\n",
        "El modelo de Regresión Logística fue utilizado como base para la versión MVP.\n",
        "\n",
        "Posteriormente, el modelo Gradient Boosting presentó un mejor desempeño general,\n",
        "por lo que fue seleccionado como el modelo final (champion model) para producción.\n",
        "\n",
        "En este notebook se documenta el entrenamiento del modelo final como referencia del\n",
        "pipeline utilizado.\n"
      ],
      "metadata": {
        "id": "4rdwGVpTfISg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separación de datos (Train / Test)"
      ],
      "metadata": {
        "id": "TH_jmWeKgMnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# ENTRENAMIENTO - Separación Train / Test\n",
        "# ======================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separación de los datos en conjuntos de entrenamiento y prueba\n",
        "# Se utiliza un split 80/20 para evaluar el desempeño del modelo\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "SSoeHAbwV_3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Separación de datos para entrenamiento y evaluación\n",
        "\n",
        "El conjunto de datos se divide en subconjuntos de entrenamiento y prueba con el\n",
        "objetivo de evaluar el desempeño del modelo sobre datos no vistos.\n",
        "\n",
        "Se utiliza una división 80/20 y estratificación sobre la variable objetivo para\n",
        "mantener la proporción de clases y evitar sesgos en la evaluación.\n"
      ],
      "metadata": {
        "id": "JQHCGvcbgYdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVALUACIÓN"
      ],
      "metadata": {
        "id": "cTnhbOACWBdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# EVALUACIÓN - Métricas del modelo\n",
        "# ======================================\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "# Predicciones del modelo sobre el conjunto de prueba\n",
        "# y_pred = gb_model.predict(X_test)\n",
        "# y_proba = gb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Cálculo de métricas\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# precision = precision_score(y_test, y_pred)\n",
        "# recall = recall_score(y_test, y_pred)\n",
        "# f1 = f1_score(y_test, y_pred)\n",
        "# roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "# Reporte de clasificación\n",
        "# print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "0lILdibkWErk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluación del modelo\n",
        "\n",
        "El desempeño del modelo se evalúa utilizando un conjunto de prueba independiente,\n",
        "empleando métricas estándar de clasificación.\n",
        "\n",
        "Se consideran métricas como accuracy, precision, recall, F1-score y ROC-AUC, las\n",
        "cuales permiten analizar tanto el rendimiento global del modelo como su capacidad\n",
        "para identificar correctamente vuelos con retraso.\n",
        "\n",
        "Estas métricas fueron utilizadas para comparar distintos modelos durante la fase\n",
        "de experimentación y respaldar la selección del modelo final.\n"
      ],
      "metadata": {
        "id": "tmS713qmhG-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimización del umbral de decisión"
      ],
      "metadata": {
        "id": "8XtJPRAsjU7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# EVALUACIÓN - Optimización del umbral\n",
        "# ======================================\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Evaluación de distintos umbrales sobre las probabilidades del modelo\n",
        "# thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "# f1_scores = []\n",
        "\n",
        "# for t in thresholds:\n",
        "#     y_pred_threshold = (y_proba >= t).astype(int)\n",
        "#     f1_scores.append(f1_score(y_test, y_pred_threshold))\n",
        "\n",
        "# Selección del umbral que maximiza el F1-score\n",
        "# best_threshold = thresholds[np.argmax(f1_scores)]\n"
      ],
      "metadata": {
        "id": "C6K0p9t4WEuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo produce probabilidades de retraso, las cuales deben convertirse en una\n",
        "decisión binaria mediante la definición de un umbral.\n",
        "\n",
        "Durante la evaluación se analizaron distintos valores de umbral con el objetivo de\n",
        "maximizar métricas relevantes para el negocio, como el F1-score, logrando un mejor\n",
        "balance entre precisión y recall.\n",
        "\n",
        "Este proceso no modifica el modelo entrenado, sino la forma en que se interpreta su\n",
        "salida en producción.\n"
      ],
      "metadata": {
        "id": "9YLZ4KbujoqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calibración de probabilidades"
      ],
      "metadata": {
        "id": "y5RLKy5Kj6YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# EVALUACIÓN - Calibración de probabilidades\n",
        "# ======================================\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Calibración de las probabilidades del modelo\n",
        "# calibrated_model = CalibratedClassifierCV(\n",
        "#     gb_model,\n",
        "#     method=\"isotonic\",\n",
        "#     cv=5\n",
        "# )\n",
        "\n",
        "# calibrated_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "MeDEXJHdWE2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La calibración de probabilidades se aplica para asegurar que las probabilidades\n",
        "predichas por el modelo reflejen de manera más fiel la frecuencia real de eventos.\n",
        "\n",
        "Este ajuste es especialmente relevante en contextos donde las probabilidades son\n",
        "consumidas por sistemas externos o utilizadas para la toma de decisiones.\n",
        "\n",
        "La calibración se realizó como una capa adicional sobre el modelo entrenado, sin\n",
        "alterar su estructura interna.\n"
      ],
      "metadata": {
        "id": "OC8tDvtbnGo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPLEMENTACIÓN"
      ],
      "metadata": {
        "id": "6DAP-sqpWFBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Serialización robusta del modelo (Bundle v2.0)"
      ],
      "metadata": {
        "id": "svi99P4wnLmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# SERIALIZACIÓN ROBUSTA - Bundle v2.0\n",
        "# ======================================\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Guardado del modelo final (champion model)\n",
        "joblib.dump(gb_model, \"champion_model_v2.pkl\")\n",
        "\n",
        "# Guardado de objetos de preprocesamiento\n",
        "joblib.dump(num_imputer, \"num_imputer_v2.pkl\")\n",
        "joblib.dump(onehot_encoder, \"onehot_encoder_v2.pkl\")\n"
      ],
      "metadata": {
        "id": "fFrWcOwSWHvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a65f251-3097-4465-a425-6568522b14e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['onehot_encoder_v2.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como paso final del trabajo se serializan de manera\n",
        "independiente los artefactos necesarios para la inferencia en producción.\n",
        "\n",
        "El bundle incluye:\n",
        "- El modelo Gradient Boosting final (champion model v2.0)\n",
        "- El imputador de variables numéricas\n",
        "- El encoder de variables categóricas\n",
        "\n",
        "Esta separación permite una integración flexible con los componentes de Backend\n",
        "y MLOps, garantizando reproducibilidad y control de versiones."
      ],
      "metadata": {
        "id": "Ahf2bwu_nz_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementación del Microservicio con FastAPI"
      ],
      "metadata": {
        "id": "FvtFxrfiTtG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se indica los pasos a realizar para la implementación del Microservicio FastAPI, en la cual se explica la estructura del proyecto y el contenido de los Scripts necesarios para implementar el poryecto, tanto en local, como en una VM (OCI, Render, AWS, etc.)"
      ],
      "metadata": {
        "id": "sMjqdRo5T2oD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Estructura del proyecto"
      ],
      "metadata": {
        "id": "UG4-K3XKUTIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la estructura que debe tener el proyecto para poder replicar el funcionamiento, en caso de querer crear el proyecto de cero a partir de este Notebook, en otro caso, se puede acceder al [Repositorio del Proyecto](https://github.com/degartHub/nocountry-h12-25-equipo27-datascience) y clonarlo en su maquina, en la carpeta `flight-delay-api` ya se encuentra la estructura correcta."
      ],
      "metadata": {
        "id": "1Wn36LUAUg23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```text\n",
        "flight-delay-api/\n",
        "├── app/\n",
        "│   ├── __init__.py\n",
        "│   ├── app.py\n",
        "│   ├── inference_pipeline.py\n",
        "│   ├── debug.py\n",
        "│   ├── explainability/\n",
        "│   │   ├── __init__.py\n",
        "│   │   └── lime_service.py\n",
        "│   └── weather/\n",
        "│       ├── __init__.py\n",
        "│       └── fallback.py\n",
        "\n",
        "├── artifacts/\n",
        "│   └── current/\n",
        "│       ├── champion_model_v2.pkl\n",
        "│       ├── lime_background_v2.pkl\n",
        "│       ├── num_imputer_v2.pkl\n",
        "│       ├── one_hot_encoder.pkl\n",
        "│       └── metadata.json\n",
        "\n",
        "├── tests/\n",
        "│   ├── __init__.py\n",
        "│   ├── test_api.py\n",
        "│   ├── test_artifacts.py\n",
        "│   └── test_inference.py\n",
        "\n",
        "├── .github/\n",
        "│   ├── cd.yml\n",
        "│   └── ci.yml\n",
        "\n",
        "├── .gitignore\n",
        "├── docker-compose.yml\n",
        "├── Dockerfile\n",
        "├── requirements.txt\n",
        "└── README.md\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j0JOIvP6UVLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dependencias del proyecto"
      ],
      "metadata": {
        "id": "gMEqd-5re3dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El proyecto depende de las siguiente librerias (las cuales estarán también definidas en el `requierements.txt`)"
      ],
      "metadata": {
        "id": "vfMSsAace6pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```text\n",
        "fastapi\n",
        "pandas\n",
        "numpy\n",
        "scikit-learn\n",
        "joblib\n",
        "uvicorn\n",
        "pydantic\n",
        "pytest\n",
        "httpx\n",
        "prometheus-client\n",
        "lime\n",
        "```"
      ],
      "metadata": {
        "id": "9E8UKsclfEJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contenido de los archivos individuales"
      ],
      "metadata": {
        "id": "jPpdPGo-bYCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todos los directorios creados para el proyecto con python, deben contener el modulo `__init__.py`, esto con el fin de que el entorno de ejecución python los reconozca como modulos Python, aún si estos modulos `__init__.py` estan vacios. Únicamente se debe garantizar su existencia.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Ahora iniciamos con el contenido de cada uno de los Scripts y archivos del proyecto.\n"
      ],
      "metadata": {
        "id": "pZtQdkiTbtEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `app.py`\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from fastapi import FastAPI, HTTPException, Response, Body\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, List\n",
        "import time\n",
        "from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST\n",
        "from app.weather.fallback import apply_fallbacks\n",
        "from app.inference_pipeline import predict, predict_batch, model\n",
        "from app.debug import get_debug_info\n",
        "\n",
        "# -----------------------\n",
        "# APP\n",
        "# -----------------------\n",
        "app = FastAPI(\n",
        "    title=\"Flight Delay Prediction API\",\n",
        "    version=\"2.0.5\"\n",
        ")\n",
        "\n",
        "# -----------------------\n",
        "# METRICAS PROMETHEUS\n",
        "# -----------------------\n",
        "REQUEST_COUNT = Counter(\n",
        "    \"api_requests_total\",\n",
        "    \"Total number of API requests\",\n",
        "    [\"endpoint\"]\n",
        ")\n",
        "\n",
        "ERROR_COUNT = Counter(\n",
        "    \"api_errors_total\",\n",
        "    \"Total number of API errors\"\n",
        ")\n",
        "\n",
        "PREDICTION_LATENCY = Histogram(\n",
        "    \"prediction_latency_seconds\",\n",
        "    \"Latency of prediction endpoint\"\n",
        ")\n",
        "\n",
        "FALLBACK_COUNT = Counter(\n",
        "    \"fallback_total\",\n",
        "    \"Total times any fallback was applied\"\n",
        ")\n",
        "\n",
        "# -----------------------\n",
        "# SCHEMAS PYDANTIC (SWAGGER)\n",
        "# -----------------------\n",
        "class PredictionInput(BaseModel):\n",
        "    aerolinea: str\n",
        "    origen: str\n",
        "    destino: str\n",
        "    fecha_partida: str\n",
        "\n",
        "    distancia_km: float = Field(..., gt=0)\n",
        "    temperatura: Optional[float] = Field(None, gt=-50, lt=60)\n",
        "    velocidad_viento: Optional[float] = Field(None, ge=0)\n",
        "    visibilidad: Optional[float] = Field(None, ge=0)\n",
        "\n",
        "\n",
        "class PredictionOutput(BaseModel):\n",
        "    prevision: str\n",
        "    probabilidad: float\n",
        "    latencia_ms: float\n",
        "    explicabilidad: Optional[dict] = None\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# ENDPOINTS\n",
        "# -----------------------\n",
        "@app.post(\"/predict\", response_model=List[PredictionOutput])\n",
        "def predict_delay(\n",
        "    data: List[PredictionInput] = Body(...),  # Siempre lista\n",
        "    explain: bool = False\n",
        "):\n",
        "    REQUEST_COUNT.labels(endpoint=\"/predict\").inc()\n",
        "    start = time.perf_counter()\n",
        "\n",
        "    try:\n",
        "        payloads = [d.model_dump() for d in data]\n",
        "\n",
        "        if len(payloads) == 1:\n",
        "            # Single record → LIME permitido\n",
        "            result = predict(payloads[0], explain=explain)\n",
        "            latency_ms = (time.perf_counter() - start) * 1000\n",
        "            result[\"latencia_ms\"] = round(latency_ms, 2)\n",
        "            return [result]  # Siempre devuelve lista para consistencia\n",
        "\n",
        "        else:\n",
        "            # Batch → no LIME\n",
        "            results = predict_batch(payloads)\n",
        "            latency_ms = (time.perf_counter() - start) * 1000\n",
        "            for r in results:\n",
        "                r[\"latencia_ms\"] = round(latency_ms, 2)\n",
        "            return results\n",
        "\n",
        "    except Exception as e:\n",
        "        ERROR_COUNT.inc()\n",
        "        raise HTTPException(status_code=400, detail=str(e))\n",
        "\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health_check():\n",
        "    return {\n",
        "        \"status\": \"ok\",\n",
        "        \"model_loaded\": model is not None,\n",
        "        \"model_type\": type(model).__name__ if model else None\n",
        "    }\n",
        "\n",
        "\n",
        "@app.get(\"/metrics\")\n",
        "def metrics() -> Response:\n",
        "    return Response(\n",
        "        generate_latest(),\n",
        "        media_type=CONTENT_TYPE_LATEST\n",
        "    )\n",
        "\n",
        "\n",
        "@app.get(\"/\", summary=\"Root endpoint para debugging y QA\")\n",
        "def root_debug():\n",
        "    REQUEST_COUNT.labels(endpoint=\"/\").inc()\n",
        "    return get_debug_info()\n",
        "```"
      ],
      "metadata": {
        "id": "d2_jDnX8cIgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `inference_pipeline.py`\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "from app.weather.fallback import apply_fallbacks\n",
        "from app.explainability.lime_service import get_top_3_influential_features\n",
        "\n",
        "# -----------------------------\n",
        "# RUTAS\n",
        "# -----------------------------\n",
        "BASE_DIR = Path(__file__).resolve().parent.parent\n",
        "ARTIFACTS_DIR = BASE_DIR / \"artifacts\" / \"current\"\n",
        "\n",
        "# -----------------------------\n",
        "# CARGA DE ARTEFACTOS\n",
        "# -----------------------------\n",
        "model = joblib.load(ARTIFACTS_DIR / \"champion_model_v2.pkl\")\n",
        "ohe = joblib.load(ARTIFACTS_DIR / \"onehot_encoder_v2.pkl\")\n",
        "num_imputer = joblib.load(ARTIFACTS_DIR / \"num_imputer_v2.pkl\")\n",
        "\n",
        "# -----------------------------\n",
        "# DEFINICIÓN DE FEATURES\n",
        "# -----------------------------\n",
        "CATEGORICAL_FEATURES = [\n",
        "    \"aerolinea\",\n",
        "    \"origen\",\n",
        "    \"destino\",\n",
        "    \"dia_semana\"\n",
        "]\n",
        "\n",
        "NUMERIC_FEATURES = [\n",
        "    \"distancia_km\",\n",
        "    \"hora_decimal\",\n",
        "    \"temperatura\",\n",
        "    \"velocidad_viento\",\n",
        "    \"visibilidad\"    \n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# PREPROCESAMIENTO BATCH\n",
        "# -----------------------------\n",
        "def preprocess_batch(payloads):\n",
        "    if isinstance(payloads, list):\n",
        "        df = pd.DataFrame(payloads)\n",
        "    elif isinstance(payloads, pd.DataFrame):\n",
        "        df = payloads.copy()\n",
        "    else:\n",
        "        raise ValueError(\"payloads debe ser lista de dicts o DataFrame\")\n",
        "\n",
        "    # Aplicar fallback fila por fila\n",
        "    df = df.apply(lambda row: apply_fallbacks(row.to_dict()), axis=1, result_type='expand')\n",
        "    df = df.drop(columns=[\"_fallback_used\"], errors=\"ignore\")  # CAMBIO: fix error 400\n",
        "\n",
        "    # Fecha → hora_decimal y dia_semana\n",
        "    dt = pd.to_datetime(df[\"fecha_partida\"], errors=\"coerce\")\n",
        "    df[\"hora_decimal\"] = dt.dt.hour + dt.dt.minute / 60\n",
        "    df[\"dia_semana\"] = dt.dt.dayofweek\n",
        "\n",
        "    # Columnas faltantes\n",
        "    for col in NUMERIC_FEATURES:\n",
        "        if col not in df.columns:\n",
        "            df[col] = 0.0\n",
        "    for col in CATEGORICAL_FEATURES:\n",
        "        if col not in df.columns:\n",
        "            df[col] = \"UNKNOWN\"\n",
        "\n",
        "    # Imputación numérica\n",
        "    df[NUMERIC_FEATURES] = num_imputer.transform(df[NUMERIC_FEATURES])\n",
        "\n",
        "    # OHE categórico\n",
        "    X_cat = ohe.transform(df[CATEGORICAL_FEATURES])\n",
        "    X_cat = pd.DataFrame(\n",
        "        X_cat,\n",
        "        columns=ohe.get_feature_names_out(CATEGORICAL_FEATURES),\n",
        "        index=df.index\n",
        "    )\n",
        "\n",
        "    X_num = df[NUMERIC_FEATURES]\n",
        "    X = pd.concat([X_num, X_cat], axis=1)\n",
        "    return X\n",
        "\n",
        "# -----------------------------\n",
        "# PREDICCIÓN SINGLE RECORD\n",
        "# -----------------------------\n",
        "def predict(payload: Dict, explain: bool = False):\n",
        "    X = preprocess_batch([payload])  # Reusar batch prep\n",
        "    proba = model.predict_proba(X)[0, 1]\n",
        "\n",
        "    threshold = 0.35\n",
        "    prediction = \"Retrasado\" if proba >= threshold else \"No Retrasado\"\n",
        "\n",
        "    result = {\n",
        "        \"prevision\": prediction,\n",
        "        \"probabilidad\": round(float(proba), 2)\n",
        "    }\n",
        "\n",
        "    if explain:\n",
        "        lime_result = get_top_3_influential_features(X)\n",
        "        result['explicabilidad'] = {\n",
        "            'metodo': 'LIME',\n",
        "            'top_3_features': lime_result['top_3_features_influyentes']\n",
        "        }\n",
        "\n",
        "    return result\n",
        "\n",
        "# -----------------------------\n",
        "# PREDICCIÓN BATCH\n",
        "# -----------------------------\n",
        "def predict_batch(payloads: List[Dict]):\n",
        "    X = preprocess_batch(payloads)\n",
        "    probas = model.predict_proba(X)[:, 1]\n",
        "\n",
        "    threshold = 0.35\n",
        "    predictions = [\"Retrasado\" if p >= threshold else \"No Retrasado\" for p in probas]\n",
        "\n",
        "    results = []\n",
        "    for i, p in enumerate(probas):\n",
        "        result = {\n",
        "            \"prevision\": predictions[i],\n",
        "            \"probabilidad\": round(float(p), 2)\n",
        "            # No LIME en batch\n",
        "        }\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "lZ5L-Ua8ezig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `debug.py`\n",
        "\n",
        "Este archivo corresponde al contenido del endpoint raíz `api/` esto con el fin de hacer debuggin humano y QA\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from app.inference_pipeline import model, CATEGORICAL_FEATURES, NUMERIC_FEATURES\n",
        "\n",
        "def get_debug_info():\n",
        "    return {\n",
        "        \"api_name\": \"Flight Delay Prediction API\",\n",
        "        \"version\": \"2.0.2\",\n",
        "        \"status\": \"ok\",\n",
        "        \"model_loaded\": model is not None,\n",
        "        \"model_type\": type(model).__name__ if model else None,\n",
        "        \"features\": {\n",
        "            \"categorical\": CATEGORICAL_FEATURES,\n",
        "            \"numeric\": NUMERIC_FEATURES\n",
        "        },\n",
        "        \"prediction_threshold\": 0.35,\n",
        "        \"example_payload\": {\n",
        "            \"aerolinea\": \"AZ\",\n",
        "            \"origen\": \"GIG\",\n",
        "            \"destino\": \"GRU\",\n",
        "            \"fecha_partida\": \"2025-11-10T14:30:00\",\n",
        "            \"distancia_km\": 350\n",
        "        },\n",
        "        \"links\": [\"/predict\", \"/health\", \"/metrics\"]\n",
        "    }\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "-GVa-O9mezk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `lime_service.py`\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "mport pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "# -----------------------------\n",
        "# RUTAS\n",
        "# -----------------------------\n",
        "BASE_DIR = Path(__file__).resolve().parent.parent.parent\n",
        "ARTIFACTS_DIR = BASE_DIR / \"artifacts\" / \"current\"\n",
        "\n",
        "# -----------------------------\n",
        "# CARGA ARTEFACTOS\n",
        "# -----------------------------\n",
        "model = joblib.load(ARTIFACTS_DIR / \"champion_model_v2.pkl\")\n",
        "\n",
        "# Dataset de background (MISMO orden que X_train)\n",
        "# ⚠️ Este archivo debe existir (subset del train ya preprocesado)\n",
        "X_TRAIN_LIME = joblib.load(ARTIFACTS_DIR / \"lime_background_v2.pkl\")\n",
        "\n",
        "FEATURE_NAMES = X_TRAIN_LIME.columns.tolist()\n",
        "\n",
        "# -----------------------------\n",
        "# LIME EXPLAINER (GLOBAL)\n",
        "# -----------------------------\n",
        "lime_explainer = LimeTabularExplainer(\n",
        "    training_data=X_TRAIN_LIME.values,\n",
        "    feature_names=FEATURE_NAMES,\n",
        "    class_names=[\"No Retrasado\", \"Retrasado\"],\n",
        "    mode=\"classification\",\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# FUNCIÓN PRINCIPAL (DA → PROD)\n",
        "# -----------------------------\n",
        "def get_top_3_influential_features(\n",
        "    instance: pd.DataFrame,\n",
        "    n_features: int = 12\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Implementación productiva EXACTA del protocolo DA.\n",
        "    \"\"\"\n",
        "\n",
        "    instance_values = instance.values[0]\n",
        "\n",
        "    explanation = lime_explainer.explain_instance(\n",
        "        instance_values,\n",
        "        model.predict_proba,\n",
        "        num_features=n_features\n",
        "    )\n",
        "\n",
        "    pred_prob = model.predict_proba(instance)[0]\n",
        "    pred_class = model.predict(instance)[0]\n",
        "\n",
        "    prob_retraso = pred_prob[1]\n",
        "\n",
        "    top_contributions = explanation.as_list()[:3]\n",
        "\n",
        "    top_3 = []\n",
        "    for feature_desc, weight in top_contributions:\n",
        "        direction = (\n",
        "            \"a favor del retraso\"\n",
        "            if weight > 0\n",
        "            else \"en contra del retraso\"\n",
        "        )\n",
        "\n",
        "        top_3.append({\n",
        "            \"feature\": feature_desc,\n",
        "            \"weight\": round(float(weight), 4),\n",
        "            \"direction\": direction\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"prediccion\": int(pred_class),\n",
        "        \"prevision\": \"Retrasado\" if pred_class == 1 else \"No Retrasado\",\n",
        "        \"probabilidad_retraso\": round(float(prob_retraso), 4),\n",
        "        \"top_3_features_influyentes\": top_3\n",
        "    }\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "cByCv7gQz0Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `fallback.py`\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from typing import Dict\n",
        "\n",
        "# Todas las features que el modelo espera\n",
        "DEFAULT_NUMERIC_FEATURES = {\n",
        "    \"distancia_km\": 0.0,\n",
        "    \"temperatura\": 0.0,\n",
        "    \"velocidad_viento\": 5.0,\n",
        "    \"visibilidad\": 10000.0,    \n",
        "}\n",
        "\n",
        "def apply_fallbacks(data: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Garantiza que todas las features numéricas requeridas\n",
        "    por el modelo existan antes de crear el DataFrame.\n",
        "    \"\"\"\n",
        "    enriched = data.copy()\n",
        "    fallback_used = False\n",
        "\n",
        "    for feature, default_value in DEFAULT_NUMERIC_FEATURES.items():\n",
        "        if feature not in enriched or enriched[feature] is None:\n",
        "            enriched[feature] = default_value\n",
        "            fallback_used = True\n",
        "\n",
        "    enriched[\"_fallback_used\"] = fallback_used\n",
        "    return enriched\n",
        "```"
      ],
      "metadata": {
        "id": "QPI_opPC0MYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `metadata.json`\n",
        "\n",
        "A este archivo se le pueden hacer muchas mejoras para optimización de todo el servicio y una implementación de buenas prácticas.\n",
        "\n",
        "---\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"model_name\": \"flight_delay_gradient_boosting\",\n",
        "  \"version\": \"2.0.0\",\n",
        "  \"framework\": \"scikit-learn\",\n",
        "  \"python_version\": \"3.11.9\",\n",
        "  \"trained_at\": \"2026-01-12T14:22:00Z\",\n",
        "  \"features\": [\n",
        "    \"aerolinea\",\n",
        "    \"origen\",\n",
        "    \"destino\",\n",
        "    \"distancia_km\",\n",
        "    \"hora_decimal\",\n",
        "    \"temperatura\",\n",
        "    \"velocidad_viento\",\n",
        "    \"visibilidad\",\n",
        "    \"recent_delay_in_origin\"\n",
        "  ],\n",
        "  \"threshold\": 0.35\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "u-W2A5Yn0hoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `test_api.py`\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from fastapi.testclient import TestClient\n",
        "from app.app import app\n",
        "\n",
        "client = TestClient(app)\n",
        "\n",
        "def test_predict_ok():\n",
        "    payload = {\n",
        "        \"aerolinea\": \"AZ\",\n",
        "        \"origen\": \"GIG\",\n",
        "        \"destino\": \"GRU\",\n",
        "        \"fecha_partida\": \"2025-11-10T14:30:00\",\n",
        "        \"distancia_km\": 350\n",
        "    }\n",
        "\n",
        "    response = client.post(\"/predict\", json=payload)\n",
        "\n",
        "    assert response.status_code == 200\n",
        "\n",
        "    data = response.json()\n",
        "\n",
        "    assert \"prevision\" in data\n",
        "    assert \"probabilidad\" in data\n",
        "\n",
        "    assert data[\"prevision\"] in [\"Retrasado\", \"No Retrasado\"]\n",
        "    assert 0.0 <= data[\"probabilidad\"] <= 1.0\n",
        "```"
      ],
      "metadata": {
        "id": "VI7B71i71Mqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `test_artifacts.py`\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from app.inference_pipeline import model, ohe, scaler\n",
        "\n",
        "def test_artifacts_loaded():\n",
        "    \"\"\"Testea que el modelo, scaler y encoder estan cargados correctamente.\"\"\"\n",
        "    assert model is not None, \"Model is not loaded\"\n",
        "    assert ohe is not None, \"One-Hot Encoder is not loaded\"\n",
        "    assert scaler is not None, \"Scaler is not loaded\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "xAOG70oneznm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `test_inference.py`\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from app.inference_pipeline import predict\n",
        "\n",
        "payload = {\n",
        "    \"aerolinea\": \"AZ\",\n",
        "    \"origen\": \"GIG\",\n",
        "    \"destino\": \"GRU\",\n",
        "    \"fecha_partida\": \"2025-11-10T14:30:00\",\n",
        "    \"distancia_km\": 350,\n",
        "    \"temperatura\": 22,\n",
        "    \"velocidad_viento\": 5,\n",
        "    \"visibilidad\": 10000\n",
        "}\n",
        "\n",
        "result = predict(payload, explain=True)\n",
        "print(result)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "b3s7AKJx1q3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `.gitgnore`\n",
        "\n",
        "Este archivo tiene la intención de evitar que los directorios y dependencias creadas por el entorno virtual de `Python` (`venv`, `Conda`, etc.) se suban al repositorio.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Entornos virtuales\n",
        "venv/\n",
        ".env/\n",
        ".env\n",
        "\n",
        "# Byte-compiled\n",
        "__pycache__/\n",
        "*.pyc\n",
        "\n",
        "# Pytest\n",
        ".pytest_cache/\n",
        "\n",
        "# VS Code\n",
        ".vscode/\n",
        "\n",
        "# OS\n",
        ".DS_Store\n",
        "Thumbs.db\n",
        "\n",
        "# Logs\n",
        "*.log\n",
        "\n",
        "#keys\n",
        "keys/\n",
        "*.key\n",
        "*.pub\n",
        "```"
      ],
      "metadata": {
        "id": "X6otE9Z11y1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `docker-compose.yml` LOCAL\n",
        "\n",
        "Este archivo debe estar en la raíz del proyecto,para testear en docker local o en `Codespaces`\n",
        "\n",
        "---\n",
        "\n",
        "```yaml\n",
        "services:\n",
        "  api:\n",
        "    build: .\n",
        "    container_name: flight-delay-api\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    restart: unless-stopped\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "uE-8uazq2sbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `docker-compose.yml` VM (OCI, AWS, Render, etc.)\n",
        "\n",
        "Este archivo **NO** debe estar en el repositorio local, esta es la versión que se construye en la VM del servicio para `deploy` haciendo uso de *CI/CD* y `GitHub Actions`.\n",
        "\n",
        "---\n",
        "\n",
        "```yaml\n",
        "version: \"3.9\"\n",
        "\n",
        "services:\n",
        "  api:\n",
        "    image: ghcr.io/wolganstark/flight-delay-api:${IMAGE_TAG}\n",
        "    container_name: flight-delay-api\n",
        "    ports:\n",
        "      - \"8000:8000\"\n",
        "    restart: unless-stopped\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "xV5SIK_nVjkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `Dockerfile`\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "FROM python:3.11-slim\n",
        "\n",
        "#Evita archivos .pyc y buffers\n",
        "\n",
        "\n",
        "ENV PYTHONDONTWRITEBYTECODE=1\n",
        "ENV PYTHONUNBUFFERED=1\n",
        "WORKDIR /app\n",
        "\n",
        "#Dependencias\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "#Codigo\n",
        "COPY app/ ./app/\n",
        "COPY artifacts/ ./artifacts/\n",
        "\n",
        "EXPOSE 8000\n",
        "\n",
        "CMD [\"uvicorn\", \"app.app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        "```"
      ],
      "metadata": {
        "id": "YK7Y6Lcg3G6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `requirements.txt`\n",
        "\n",
        "---\n",
        "\n",
        "```text\n",
        "fastapi==0.123.10\n",
        "pandas==2.2.2\n",
        "numpy==2.0.2\n",
        "scikit-learn==1.6.1\n",
        "joblib==1.5.3\n",
        "uvicorn==0.38.0\n",
        "pydantic==2.12.3\n",
        "pytest==9.0.2\n",
        "httpx==0.28.1\n",
        "prometheus-client==0.23.1\n",
        "lime==0.2.0.1\n",
        "```"
      ],
      "metadata": {
        "id": "5wNggOhF3TA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mejoras futuras"
      ],
      "metadata": {
        "id": "sUNupW5f3v_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El proyecto puede tener mejoras futuras que permitan una construcción más robusta o la implementación de más Features:\n",
        "\n",
        "\n",
        "\n",
        "*   Prometheus: No la versión `prometheus-client`, si no la versión que genera las métricas del servicio, generalmente implementado en el puerto local 9090\n",
        "*   Streamlit: Un dashboard con Streamlit para generar las métricas del negocio.\n",
        "*   Metadata.json: Mejorar el `metadata.json` para la reproducibilidad del servicio y evitar inconvenientes con los errores del orden de las columnas y el uso de los `transformers`, esto incluye la refactorización del codigo haciendo uso de este archivo.\n",
        "\n"
      ],
      "metadata": {
        "id": "5GfCiWP83ymX"
      }
    }
  ]
}